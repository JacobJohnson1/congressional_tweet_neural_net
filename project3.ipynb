{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>party_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"RT @KUSINews: One of our longtime viewers wa...</td>\n",
       "      <td>KUSI</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>b\"Today I'm urging the @CDCgov to immediately ...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>111</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Tomorrow, #MO03 seniors graduate from Calvar...</td>\n",
       "      <td>MO03</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>b'Congrats to #TeamUSA and Canton Native @JGre...</td>\n",
       "      <td>TeamUSA WorldJuniors</td>\n",
       "      <td>3</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Pleased to support @amergateways at their Ju...</td>\n",
       "      <td>ImmigrantHeritageMonth</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   favorite_count                                          full_text  \\\n",
       "0               0  b\"RT @KUSINews: One of our longtime viewers wa...   \n",
       "1             258  b\"Today I'm urging the @CDCgov to immediately ...   \n",
       "2               0  b'Tomorrow, #MO03 seniors graduate from Calvar...   \n",
       "3               9  b'Congrats to #TeamUSA and Canton Native @JGre...   \n",
       "4               3  b'Pleased to support @amergateways at their Ju...   \n",
       "\n",
       "                 hashtags  retweet_count party_id  \n",
       "0                    KUSI             10        R  \n",
       "1             Coronavirus            111        R  \n",
       "2                    MO03              2        R  \n",
       "3    TeamUSA WorldJuniors              3        R  \n",
       "4  ImmigrantHeritageMonth              3        D  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/jacobjohnson/data_sets/congressional_tweet_training_data.csv', names=['favorite_count', 'full_text', 'hashtags', 'retweet_count', 'year', 'party_id'], \n",
    "                    # dtype={'favorite_count': int, 'full_text': str, 'hashtags': str, 'retweet_count': int, 'year': int, 'party_id': str}, \n",
    "                    skipinitialspace=True, skiprows=1, sep=',')\n",
    "\n",
    "test_df = pd.read_csv('/Users/jacobjohnson/data_sets/congressional_tweet_test_data.csv', names=['id', 'favorite_count_test', 'full_text_test', 'hashtags_test', 'retweet_count_test', 'year', 'party'], \n",
    "                    # dtype={'id': int, 'favorite_count': int, 'full_text': str, 'hashtags': str, 'retweet_count': int, 'year': int, 'party': str}, \n",
    "                    skipinitialspace=True, skiprows=1, sep=',')\n",
    "\n",
    "train_df.pop('year')\n",
    "test_df.pop('year')\n",
    "\n",
    "# test_df.head()\n",
    "train_df.head()\n",
    "\n",
    "# target variable\n",
    "# party = train_df.pop('party_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474242 training examples\n",
      "59280 validation examples\n",
      "59281 test examples\n"
     ]
    }
   ],
   "source": [
    "train, val, test = np.split(train_df.sample(frac=1), [int(0.8*len(train_df)), int(0.9*len(train_df))])\n",
    "\n",
    "print(len(train), 'training examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  names = df.pop('party_id')\n",
    "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), names))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/brcqg8zx7xg31hjn_xbd2jc80000gp/T/ipykernel_48827/2315459290.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
      "2022-05-06 16:14:14.098628: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/nf/brcqg8zx7xg31hjn_xbd2jc80000gp/T/ipykernel_48827/2315459290.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
      "/var/folders/nf/brcqg8zx7xg31hjn_xbd2jc80000gp/T/ipykernel_48827/2315459290.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 5\n",
    "# train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['favorite_count', 'full_text', 'hashtags', 'retweet_count', 'party_id']\n",
      "A batch of hashtags: tf.Tensor(\n",
      "[[b'HappyHolidays']\n",
      " [b'SickleCellAwareness']\n",
      " [b'Hero']\n",
      " [b'OpportunityZones']\n",
      " [b'constitutionday2020']\n",
      " [b'PittsburghKneelers']\n",
      " [b'VA10']\n",
      " [b'Gitmo']\n",
      " [b'ProtectAllWorkers']\n",
      " [b'NY13']\n",
      " [b'DREAMers DreamAct']\n",
      " [b'WA01']\n",
      " [b'InternationalWomensDay']\n",
      " [b'ACA CBCHBT']\n",
      " [b'IL02Proud']\n",
      " [b'GetCovered']\n",
      " [b'whokilledlaurapalmer twinpeaks']\n",
      " [b'NY21']\n",
      " [b'Gorsuch SCOTUS']\n",
      " [b'smallbiz']\n",
      " [b'EqualityAct']\n",
      " [b'ProtectOurCare']\n",
      " [b'Trumpcare']\n",
      " [b'NationalFarmersDay']\n",
      " [b'MI08']\n",
      " [b'COVID19 CA29']\n",
      " [b'WRRDA America']\n",
      " [b'ClintonPoliceDept ThinBlueLine ultimatesacrifice']\n",
      " [b'Trump TPS']\n",
      " [b'WRDA2020 CA38']\n",
      " [b'EstamosUnidosVE Venezuela']\n",
      " [b'NARLegislative']\n",
      " [b'SCOTUS Obamacare ACA tcot hcr']\n",
      " [b'AffordableCareAct ACAWorks 20MillionStrong']\n",
      " [b'ACA ACATurns3']\n",
      " [b'OH2']\n",
      " [b'FL25']\n",
      " [b'HurricaneDorian']\n",
      " [b'wontlast summerscomingsoon']\n",
      " [b'TrumpCaves China Trump']\n",
      " [b'ProtectOurCare']\n",
      " [b'ACArepeal']\n",
      " [b'DontMessWithUSPS']\n",
      " [b'HandsOffMyBC']\n",
      " [b'MasterpieceCakeshop equalrights']\n",
      " [b'upstander upstander BullyingPreventionMonth']\n",
      " [b'Trainwreck PJNET']\n",
      " [b'Obamacare']\n",
      " [b'Connecticut']\n",
      " [b'Stopthetaxhike']\n",
      " [b'coronavirus']\n",
      " [b'USMCA']\n",
      " [b'TruthExposed']\n",
      " [b'taxes taxrelief jobs 4jobs']\n",
      " [b'HolocaustRemembranceDay NeverAgain']\n",
      " [b'COVID19']\n",
      " [b'HappyValentinesDay']\n",
      " [b'SaveLWCF']\n",
      " [b'NJ5']\n",
      " [b'CA34 2020Census']\n",
      " [b'ERANOW WeWontGoBack WeWontStop']\n",
      " [b'SleepyHollowFire']\n",
      " [b'COVID19']\n",
      " [b'Today']\n",
      " [b'FollowTheFacts']\n",
      " [b'ForThePeople']\n",
      " [b'WA02 COVID19']\n",
      " [b'Binghamton NY22']\n",
      " [b'LaborDay LaborDay2016']\n",
      " [b'Navy WeWantBeards tcot']\n",
      " [b'flsen sayfie nixnelson']\n",
      " [b'HeIsRisen']\n",
      " [b'ThankYou Vets']\n",
      " [b'SFRC']\n",
      " [b'Yeson1 TeamCap']\n",
      " [b'BalancedBudget']\n",
      " [b'TX01']\n",
      " [b'JobGrowth CamdenNJ']\n",
      " [b'Speaker']\n",
      " [b'Peoria']\n",
      " [b'COVID']\n",
      " [b'ZuckerbergHearing']\n",
      " [b'bipartisan StrategicNationalStockpile']\n",
      " [b'IranDeal']\n",
      " [b'covid19']\n",
      " [b'TheyFeelPain prolife']\n",
      " [b'FargoMarathon fargo']\n",
      " [b'Monday NotMonday']\n",
      " [b'covid19 STL ForThePeople']\n",
      " [b'equalpay LatinaEqualPayDay']\n",
      " [b'SOTU2020']\n",
      " [b'veteran']\n",
      " [b'LGBT']\n",
      " [b'RestrictFirstUse']\n",
      " [b'DayOfRemembrance']\n",
      " [b'TrumpShutdown CHIPfunding']\n",
      " [b'COVID19']\n",
      " [b'COARA']\n",
      " [b'CDA230']\n",
      " [b'WednesdayWisdom WednesdayMotivation wednesdaythoughts tcot']\n",
      " [b'kssen']\n",
      " [b'Capitol']\n",
      " [b'TampaBay PreExistingConditions sabotage']\n",
      " [b'FBI2MD']\n",
      " [b'TaxReform']\n",
      " [b'terrorist']\n",
      " [b'agriculture']\n",
      " [b'SRAAct2020']\n",
      " [b'TrumpCare']\n",
      " [b'WWII DDay74 Normandy DDay']\n",
      " [b'COVID19']\n",
      " [b'Georgia OTD']\n",
      " [b'taxreform Ohio taxcode Ohioans']\n",
      " [b'IAmAScienceDiplomat']\n",
      " [b'GoPackGo']\n",
      " [b'thingsyoucanlearnfromliberals cutwaste']\n",
      " [b'DDay76']\n",
      " [b'COVID19']\n",
      " [b'ArchitectsOfDisaster']\n",
      " [b'SaveTPS']\n",
      " [b'TN04 ObamaCare']\n",
      " [b'cancer']\n",
      " [b'POWMIARecognitionDay']\n",
      " [b'DefendOurDemocracy ImpeachmentVote']\n",
      " [b'Lansing MI08']\n",
      " [b'SaveUSPS']\n",
      " [b'DomesticViolenceFacts DVAM2017']\n",
      " [b'CA21']\n",
      " [b'fishing']\n",
      " [b'PopeInDC']\n",
      " [b'healthcare']\n",
      " [b'CarrFire CampFire']\n",
      " [b'USMCA']\n",
      " [b'standwithrand usconstitution']\n",
      " [b'STOCKAct']\n",
      " [b'startups StartupDay']\n",
      " [b'CA44 Compton']\n",
      " [b'FillTheSeat']\n",
      " [b'NotOneCent']\n",
      " [b'PeaceOfficersMemorialDay']\n",
      " [b'OBX']\n",
      " [b'SmallBusinessWeek']\n",
      " [b'gapol']\n",
      " [b'Honored']\n",
      " [b'HR1014']\n",
      " [b'GSA']\n",
      " [b'ICYMI']\n",
      " [b'Houston']\n",
      " [b'ACStrategy']\n",
      " [b'winning']\n",
      " [b'PrideMonth']\n",
      " [b'TechQuity CBCTech2020']\n",
      " [b'NC10 BuncombeCounty RutherfordCounty WNC']\n",
      " [b'BetterCare']\n",
      " [b'BibiSpeech tcot']\n",
      " [b'SCOTUS']\n",
      " [b'USMCAnow']\n",
      " [b'smallbiz']\n",
      " [b'AirForce']\n",
      " [b'Obamaquester']\n",
      " [b'ag commodity FarmBill Minnesota farmers ranchers']\n",
      " [b'Postalbanking']\n",
      " [b'ShieldAct']\n",
      " [b'Phoenix']\n",
      " [b'healthcare']\n",
      " [b'Henrico VA07']\n",
      " [b'CriminalJusticeReform']\n",
      " [b'DemDebate']\n",
      " [b'redraiders Gunsup WreckEm']\n",
      " [b'higov']\n",
      " [b'PorterRanchGasLeak']\n",
      " [b'ar4']\n",
      " [b'HR8']\n",
      " [b'UGA bulldognation godawgs']\n",
      " [b'Iran']\n",
      " [b'WomensHistoryMonth MeToo TimesUp']\n",
      " [b'SaveObamacare HealthCare NeverGiveUp']\n",
      " [b'GetWell']\n",
      " [b'famliesbelongtogether']\n",
      " [b'GOPShutdown']\n",
      " [b'WorkersMemorialDay']\n",
      " [b'Texas border txgop txcot DFW TX']\n",
      " [b'ACA RI']\n",
      " [b'OC']\n",
      " [b'AskTheExperts']\n",
      " [b'Remembering911']\n",
      " [b'paidleave FAMILYAct Paidleave FMLA25']\n",
      " [b'tcot FakeNews']\n",
      " [b'Trump Obama jobs']\n",
      " [b'WRRDA NY27']\n",
      " [b'GetCovered']\n",
      " [b'FlagDay']\n",
      " [b'pray']\n",
      " [b'RenewUI ROC']\n",
      " [b'KidVid']\n",
      " [b'DreamAct JewsForDreamers']\n",
      " [b'ObamaCare KlineAsksPotus']\n",
      " [b'Alamo WomensHistoryMonth TexasIndependenceDay RemembertheAlamo']\n",
      " [b'DoddFrank CHOICEAct']\n",
      " [b'ScottPruitt']\n",
      " [b'techgop']\n",
      " [b'Obamacare']\n",
      " [b'MobileOffice AR3']\n",
      " [b'LastSOTU']\n",
      " [b'Trumpcare CBCOnHealthcare']\n",
      " [b'MemorialDay CA08']\n",
      " [b'taxreform NDAA']\n",
      " [b'NationalPreparednessMonth COVID19']\n",
      " [b'DefundObamacare']\n",
      " [b'SOTU TimesUp SOTUBlackout']\n",
      " [b'Preparedness PreparedNotScared']\n",
      " [b'WomensMarch ProtectOurCare']\n",
      " [b'KS03']\n",
      " [b'MedalofHonorDay']\n",
      " [b'OurOcean']\n",
      " [b'MaxineWaters']\n",
      " [b'KimJongUn']\n",
      " [b'FrontlinePBS']\n",
      " [b'IWD2019']\n",
      " [b'LACounty']\n",
      " [b'Texas dfw']\n",
      " [b'Democrat tcot']\n",
      " [b'Rightowork 4freedoms sayfie']\n",
      " [b'DACA DAPA']\n",
      " [b'CaliforniaWildfires']\n",
      " [b'COVID_19']\n",
      " [b'Buckeyes MarchMadness']\n",
      " [b'Putnam']\n",
      " [b'BloodySunday']\n",
      " [b'TaxCutAndJobsAct']\n",
      " [b'GirlsGoCyberStart']\n",
      " [b'EndGunViolence NoRepublicanAction']\n",
      " [b'2A']\n",
      " [b'ROC']\n",
      " [b'BaldwinHills']\n",
      " [b'FamiliesFirst COVID19']\n",
      " [b'NeverForget1915']\n",
      " [b'SC']\n",
      " [b'AHCA']\n",
      " [b'Thanksgiving']\n",
      " [b'GOPTaxPlan']\n",
      " [b'CA39 CARESAct']\n",
      " [b'ProtectOurCare']\n",
      " [b'COVID19 IA03']\n",
      " [b'RaiseTheWage']\n",
      " [b'MarchOnWashington']\n",
      " [b'Queens Bronx']\n",
      " [b'science']\n",
      " [b'TX27 smallbiz']\n",
      " [b'FakeEmergency']\n",
      " [b'CombatCOVID19 MilitaryAppreciationMonth']\n",
      " [b'WIC']\n",
      " [b'GOPshutdown']\n",
      " [b'RaiseTheWage']\n",
      " [b'ChooseLife prolife']\n",
      " [b'HarveyRelief']], shape=(256, 1), dtype=string)\n",
      "A batch of targets: tf.Tensor(\n",
      "[b'D' b'D' b'R' b'R' b'R' b'R' b'D' b'R' b'D' b'D' b'D' b'D' b'D' b'D'\n",
      " b'D' b'D' b'R' b'R' b'R' b'R' b'D' b'D' b'D' b'R' b'R' b'D' b'R' b'R'\n",
      " b'D' b'D' b'R' b'D' b'R' b'D' b'D' b'R' b'R' b'R' b'R' b'D' b'D' b'D'\n",
      " b'D' b'D' b'D' b'D' b'R' b'R' b'D' b'R' b'R' b'R' b'D' b'R' b'D' b'D'\n",
      " b'R' b'D' b'D' b'D' b'D' b'R' b'D' b'R' b'D' b'D' b'D' b'R' b'D' b'R'\n",
      " b'R' b'R' b'R' b'R' b'D' b'R' b'R' b'D' b'D' b'D' b'R' b'R' b'R' b'R'\n",
      " b'D' b'R' b'R' b'D' b'D' b'D' b'D' b'D' b'D' b'D' b'D' b'D' b'D' b'R'\n",
      " b'R' b'R' b'R' b'R' b'D' b'D' b'R' b'R' b'D' b'R' b'D' b'R' b'D' b'R'\n",
      " b'R' b'D' b'R' b'R' b'R' b'R' b'R' b'D' b'R' b'R' b'R' b'D' b'R' b'D'\n",
      " b'D' b'R' b'D' b'R' b'D' b'R' b'R' b'R' b'D' b'D' b'D' b'R' b'R' b'R'\n",
      " b'R' b'R' b'R' b'R' b'R' b'D' b'D' b'D' b'D' b'R' b'D' b'D' b'R' b'D'\n",
      " b'R' b'D' b'R' b'R' b'R' b'R' b'D' b'D' b'D' b'R' b'D' b'D' b'D' b'D'\n",
      " b'R' b'D' b'D' b'R' b'D' b'R' b'R' b'D' b'D' b'D' b'D' b'D' b'D' b'R'\n",
      " b'D' b'D' b'D' b'R' b'D' b'R' b'R' b'R' b'D' b'R' b'R' b'D' b'D' b'D'\n",
      " b'R' b'R' b'R' b'D' b'R' b'R' b'R' b'R' b'D' b'R' b'R' b'R' b'R' b'D'\n",
      " b'R' b'D' b'R' b'R' b'D' b'D' b'D' b'D' b'D' b'D' b'R' b'R' b'R' b'D'\n",
      " b'R' b'R' b'R' b'D' b'D' b'R' b'D' b'D' b'R' b'D' b'D' b'D' b'D' b'R'\n",
      " b'R' b'D' b'D' b'D' b'D' b'D' b'D' b'R' b'D' b'D' b'R' b'D' b'R' b'D'\n",
      " b'D' b'D' b'R' b'R'], shape=(256,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of hashtags:', train_features['hashtags'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  normalizer.adapt(feature_ds)\n",
    "  return normalizer\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  if dtype == 'string':\n",
    "    index = layers.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  index.adapt(feature_ds)\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features.\n",
    "\n",
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "for header in ['favorite_count', 'retweet_count']:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['full_text', 'hashtags']\n",
    "\n",
    "for header in text_cols:\n",
    "  text_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                               dataset=train_ds,\n",
    "                                               dtype='string',\n",
    "                                               max_tokens=None)\n",
    "  encoded_text_col = encoding_layer(text_col)\n",
    "  all_inputs.append(text_col)\n",
    "  encoded_features.append(encoded_text_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# party_id_col = tf.keras.Input(shape=(1,), name='party_id', dtype='string')\n",
    "\n",
    "# encoding_layer = get_category_encoding_layer(name='party_id',\n",
    "#                                              dataset=train_ds,\n",
    "#                                              dtype='string',\n",
    "#                                              max_tokens=None)\n",
    "# encoded_party_id_col = encoding_layer(party_id_col)\n",
    "# all_inputs.append(party_id_col)\n",
    "# encoded_features.append(encoded_party_id_col)\n",
    "\n",
    "\n",
    "# test_party_id_col = train_features['party_id']\n",
    "# test_party_id_layer = get_category_encoding_layer(name='party_id',\n",
    "#                                              dataset=train_ds,\n",
    "#                                              dtype='string',\n",
    "#                                              max_tokens=None)\n",
    "# test_party_id_layer(test_party_id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TO TEST ENCODING\n",
    "\n",
    "# test_retweet_count_col = train_features['retweet_count']\n",
    "# test_retweet_count_layer = get_normalization_layer(name='retweet_count', dataset=train_ds)\n",
    "# test_retweet_count_layer(test_retweet_count_col)\n",
    "\n",
    "# test_favorite_count_col = train_features['favorite_count']\n",
    "# test_favorite_count_layer = get_normalization_layer(name='favorite_count', dataset=train_ds)\n",
    "# test_favorite_count_layer(test_favorite_count_col)\n",
    "\n",
    "# test_full_text_col = train_features['full_text']\n",
    "# test_full_text_layer = get_category_encoding_layer(name='full_text', dataset=train_ds, dtype='string')\n",
    "# test_full_text_layer(test_full_text_col)\n",
    "\n",
    "# test_hashtags_col = train_features['hashtags']\n",
    "# test_hashtags_layer = get_category_encoding_layer(name='hashtags', dataset=train_ds, dtype='string')\n",
    "# test_hashtags_layer(test_hashtags_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'favorite_count')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'retweet_count')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=string (created by layer 'full_text')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=string (created by layer 'hashtags')>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['party_id'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "2022-05-06 16:14:42.425391: W tensorflow/core/framework/op_kernel.cc:1722] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/nf/brcqg8zx7xg31hjn_xbd2jc80000gp/T/ipykernel_48827/4003320285.py\", line 1, in <cell line: 1>\n      model.fit(train_ds, epochs=10, validation_data=val_ds)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 1922, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_16404]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/nf/brcqg8zx7xg31hjn_xbd2jc80000gp/T/ipykernel_48827/4003320285.py\", line 1, in <cell line: 1>\n      model.fit(train_ds, epochs=10, validation_data=val_ds)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/losses.py\", line 1922, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_16404]"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
